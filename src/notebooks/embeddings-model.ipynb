{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semeval-embeddings",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "fwK-8CIkWjB1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SemEval 2018: Task 8 - Question classification practice notebook\n",
        "\n",
        "Using Glove embedding with 100d, trained on Twitter dataset(should improve work with non-formal text).\n",
        "Embeddings need 1-2 GB of RAM and 2-3 GB of disk space. The notebook is self-sufficient, which means it downloads and unpacks its own data, that is becuase it is intended to be run in [Google Colab](https://colab.research.google.com).\n"
      ]
    },
    {
      "metadata": {
        "id": "unYrBxQdXEN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download Glove embedding"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "b39c75f5-c43e-476a-c7f5-80d05622fa29",
        "id": "_QMFumOyWfbY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "cell_type": "code",
      "source": [
        "!wget nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-23 11:53:15--  http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip [following]\n",
            "--2018-12-23 11:53:15--  https://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408741 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  46.5MB/s    in 35s     \n",
            "\n",
            "2018-12-23 11:53:51 (41.1 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408741/1520408741]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nc4lt-lUT1cc",
        "colab_type": "code",
        "outputId": "231745f9-ba24-45a2-86de-a3a384257c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 5242484\n",
            "-rw-rw-r-- 1 root root 1021671926 Dec 23  2015 glove.twitter.27B.100d.txt\n",
            "-rw-rw-r-- 1 root root 2057595650 Dec 23  2015 glove.twitter.27B.200d.txt\n",
            "-rw-rw-r-- 1 root root  257699930 Dec 23  2015 glove.twitter.27B.25d.txt\n",
            "-rw-rw-r-- 1 root root  510889212 Dec 23  2015 glove.twitter.27B.50d.txt\n",
            "-rw-r--r-- 1 root root 1520408741 Dec 23  2015 glove.twitter.27B.zip\n",
            "drwxr-xr-x 1 root root       4096 Dec 18 20:29 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e2cdb70d-be36-46a1-c09a-cd4c8121f008",
        "id": "LlLKxwN7XVdA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1047
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip glove.twitter.27B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.twitter.27B.zip\n",
            "replace glove.twitter.27B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f112d463156d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip glove.twitter.27B.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mShell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd)\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   result = _run_command(\n\u001b[0;32m--> 436\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    437\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UVRmF7pgXW74",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ]
    },
    {
      "metadata": {
        "id": "gn5MSfwIXcfk",
        "colab_type": "code",
        "outputId": "730ec712-97ad-40c0-b52a-d192440e4d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -O 'dataset.zip' 'https://competitions.codalab.org/my/datasets/download/30915784-67bb-4974-8c24-21a7ec86f587'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-23 14:03:45--  https://competitions.codalab.org/my/datasets/download/30915784-67bb-4974-8c24-21a7ec86f587\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 134.158.75.178\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|134.158.75.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/77777/train_and_dev_sets_questions_and_an.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c10a894860b7e12bc63fd4ba116f59fb458a06e9d899ebc6ab7c207d5b03f65d&X-Amz-Date=20181223T140335Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181223%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2018-12-23 14:03:46--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/77777/train_and_dev_sets_questions_and_an.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c10a894860b7e12bc63fd4ba116f59fb458a06e9d899ebc6ab7c207d5b03f65d&X-Amz-Date=20181223T140335Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20181223%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 292440 (286K) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 285.59K   507KB/s    in 0.6s    \n",
            "\n",
            "2018-12-23 14:03:47 (507 KB/s) - ‘dataset.zip’ saved [292440/292440]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OSRboGuiXlS8",
        "colab_type": "code",
        "outputId": "ccbd492f-af2c-49c8-fe4e-03d38d98cf92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip\n",
        "!rm -rf __MACOSXb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  dataset.zip\n",
            "  inflating: questions_train.xml     \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._questions_train.xml  \n",
            "  inflating: questions_dev.xml       \n",
            "  inflating: __MACOSX/._questions_dev.xml  \n",
            "  inflating: answers_train.xml       \n",
            "  inflating: __MACOSX/._answers_train.xml  \n",
            "  inflating: answers_dev.xml         \n",
            "  inflating: __MACOSX/._answers_dev.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aYUa1K6Prsai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data setup"
      ]
    },
    {
      "metadata": {
        "id": "lrQwiipt6teN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "az76xA8UVHo1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 200\n",
        "MAX_NUM_WORDS = 10000\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "glove_embeddings_file = \"./glove.twitter.27B.100d.txt\"\n",
        "questions_train_file = \"./questions_train.xml\"\n",
        "questions_dev_file = \"./questions_dev.xml\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfkHnbRWWKMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class XMLParser:\n",
        "    \"\"\"Parser assumes the first level of xml tags are to be transformed\n",
        "    to rows in a Pandas dataframe. For each of the first-level tags it takes\n",
        "    all of their subtags and attributes, and puts them as columns to\n",
        "    the current row in the dataframe.\"\"\"\n",
        "\n",
        "    def __init__(self, xml_data):\n",
        "        self.root = ET.XML(xml_data)\n",
        "\n",
        "    def parse_root(self, root):\n",
        "        \"\"\"Return a list of dictionaries from the text\n",
        "         and attributes of the children under this XML root.\"\"\"\n",
        "        return [self.parse_element(child) for child in iter(root)]\n",
        "\n",
        "    def parse_element(self, element, parsed=None):\n",
        "        \"\"\" Collect {key:attribute} and {tag:text} from the XML\n",
        "         element and all its children into a single dictionary of strings.\"\"\"\n",
        "\n",
        "        if parsed is None:\n",
        "            parsed = dict()\n",
        "\n",
        "        if element.tag == \"RelComment\":\n",
        "            return parsed\n",
        "\n",
        "        for key in element.keys():\n",
        "            if key not in parsed:\n",
        "                parsed[key] = element.attrib.get(key)\n",
        "            else:\n",
        "                raise ValueError('Duplicate attribute {0} = {1}, prev = {2}' \\\n",
        "                                 .format(key,\n",
        "                                         element.attrib.get(key),\n",
        "                                         parsed[key]))\n",
        "\n",
        "        for child in iter(element):\n",
        "            if child.tag == \"RelQSubject\" or child.tag == \"RelQBody\":\n",
        "                parsed[child.tag] = child.text\n",
        "            else:\n",
        "                self.parse_element(child, parsed)\n",
        "\n",
        "        return parsed\n",
        "\n",
        "    def to_df(self):\n",
        "        \"\"\" Initiate the root XML, parse it, and return a dataframe\"\"\"\n",
        "        structure_data = self.parse_root(self.root)\n",
        "        return pd.DataFrame(structure_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nDUAMapUVg75",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def df_from_xml_file(filename):\n",
        "    \"\"\"Make dataframe from xml file(not recursive)\"\"\"\n",
        "    with open(filename, 'r') as content_file:\n",
        "         content = content_file.read()\n",
        "\n",
        "    xml = XMLParser(content)\n",
        "    xml_df = xml.to_df()\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def make_data(df, class_map):\n",
        "    \"\"\"Compact and transform the dataframe needed for classification.\n",
        "    Returns:\n",
        "        x - 1d nparray with docs\n",
        "        y - 1d nparray with classes as integers\n",
        "        data - dataframe with only the needed features for classification\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame({\n",
        "        'id': df.THREAD_SEQUENCE,\n",
        "        'subject': df.RelQSubject,\n",
        "        'question': df.RelQBody,\n",
        "        'type': df.RELQ_FACT_LABEL,\n",
        "    })\n",
        "\n",
        "    data.question = data.question.fillna(\"\")\n",
        "    data.question = data.subject + \"\\t\"  + data.question\n",
        "    data = data.drop(['subject'], axis=1)\n",
        "    \n",
        "    x, y = data.question.values, None\n",
        "    if class_map:\n",
        "        np.zeros( (data.type.shape[0], ) )\n",
        "        y = data.type.transform(lambda x: class_map[x]).values\n",
        "\n",
        "    return x, y, data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "82nCq7cOVhKg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "types_map = {\n",
        "    'Opinion': 0, \n",
        "    'Factual': 1, \n",
        "    'Socializing': 2\n",
        "}  \n",
        "\n",
        "questions_train_df = df_from_xml_file(questions_train_file)\n",
        "questions_test_df = df_from_xml_file(questions_dev_file)\n",
        "\n",
        "x, y, questions_train_df = make_data(question_train_df, class_map=types_map)\n",
        "x_test, _, questions_test_df = make_data(question_test_df, class_map=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TIZDrp8YuzqA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(x)\n",
        "sequences = tokenizer.texts_to_sequences(x)\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2222VCbDvCU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EvIxUBUWvq2j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(data,\n",
        "                                                  labels,\n",
        "                                                  test_size=0.20,\n",
        "                                                  random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e1nsfQ4BtBfu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model setup"
      ]
    },
    {
      "metadata": {
        "id": "mos_XVn67XSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load embeddings\n",
        "embeddings_matrix = pd.read_table(glove_embeddings_file, \n",
        "                                  sep=\" \", \n",
        "                                  index_col=0, \n",
        "                                  header=None, \n",
        "                                  quoting=csv.QUOTE_NONE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTJulqqS8aAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(embeddings_matrix.shape[0],\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embeddings_matrix.values],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3elpkdF6oOe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "pulling = GlobalMaxPooling1D()(embedded_sequences)\n",
        "fully_connected = Dense(128, activation='relu')(pulling)\n",
        "preds = Dense(3, activation='softmax')(fully_connected)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-Hc_6OO8uS-",
        "colab_type": "code",
        "outputId": "2ed5ba59-753b-4b63-a411-e914694217d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3930
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=100,\n",
        "          validation_data=(x_val, y_val))\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 200, 100)          119351700 \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 119,365,015\n",
            "Trainable params: 13,315\n",
            "Non-trainable params: 119,351,700\n",
            "_________________________________________________________________\n",
            "Train on 894 samples, validate on 224 samples\n",
            "Epoch 1/100\n",
            "894/894 [==============================] - 0s 103us/step - loss: 0.7891 - acc: 0.6588 - val_loss: 1.0946 - val_acc: 0.5402\n",
            "Epoch 2/100\n",
            "894/894 [==============================] - 0s 107us/step - loss: 0.8200 - acc: 0.6309 - val_loss: 1.0481 - val_acc: 0.5536\n",
            "Epoch 3/100\n",
            "894/894 [==============================] - 0s 111us/step - loss: 0.7878 - acc: 0.6532 - val_loss: 1.0491 - val_acc: 0.4821\n",
            "Epoch 4/100\n",
            "894/894 [==============================] - 0s 119us/step - loss: 0.8084 - acc: 0.6331 - val_loss: 1.0690 - val_acc: 0.4777\n",
            "Epoch 5/100\n",
            "894/894 [==============================] - 0s 110us/step - loss: 0.7744 - acc: 0.6465 - val_loss: 1.0563 - val_acc: 0.4911\n",
            "Epoch 6/100\n",
            "894/894 [==============================] - 0s 111us/step - loss: 0.7928 - acc: 0.6353 - val_loss: 1.0687 - val_acc: 0.5357\n",
            "Epoch 7/100\n",
            "894/894 [==============================] - 0s 114us/step - loss: 0.7919 - acc: 0.6309 - val_loss: 1.0552 - val_acc: 0.4866\n",
            "Epoch 8/100\n",
            "894/894 [==============================] - 0s 123us/step - loss: 0.7840 - acc: 0.6521 - val_loss: 1.0391 - val_acc: 0.5268\n",
            "Epoch 9/100\n",
            "894/894 [==============================] - 0s 121us/step - loss: 0.7678 - acc: 0.6633 - val_loss: 1.0325 - val_acc: 0.5357\n",
            "Epoch 10/100\n",
            "894/894 [==============================] - 0s 127us/step - loss: 0.7748 - acc: 0.6711 - val_loss: 1.0918 - val_acc: 0.5357\n",
            "Epoch 11/100\n",
            "894/894 [==============================] - 0s 117us/step - loss: 0.7721 - acc: 0.6555 - val_loss: 1.1174 - val_acc: 0.4821\n",
            "Epoch 12/100\n",
            "894/894 [==============================] - 0s 125us/step - loss: 0.7607 - acc: 0.6689 - val_loss: 1.0315 - val_acc: 0.5312\n",
            "Epoch 13/100\n",
            "894/894 [==============================] - 0s 132us/step - loss: 0.7525 - acc: 0.6857 - val_loss: 1.0832 - val_acc: 0.4866\n",
            "Epoch 14/100\n",
            "894/894 [==============================] - 0s 110us/step - loss: 0.7430 - acc: 0.6846 - val_loss: 1.0517 - val_acc: 0.5179\n",
            "Epoch 15/100\n",
            "894/894 [==============================] - 0s 108us/step - loss: 0.7384 - acc: 0.6823 - val_loss: 1.0574 - val_acc: 0.4911\n",
            "Epoch 16/100\n",
            "894/894 [==============================] - 0s 107us/step - loss: 0.7362 - acc: 0.6890 - val_loss: 1.0556 - val_acc: 0.5134\n",
            "Epoch 17/100\n",
            "894/894 [==============================] - 0s 115us/step - loss: 0.7472 - acc: 0.6689 - val_loss: 1.0918 - val_acc: 0.5357\n",
            "Epoch 18/100\n",
            "894/894 [==============================] - 0s 106us/step - loss: 0.7379 - acc: 0.6678 - val_loss: 1.1147 - val_acc: 0.4911\n",
            "Epoch 19/100\n",
            "894/894 [==============================] - 0s 118us/step - loss: 0.7112 - acc: 0.6890 - val_loss: 1.1009 - val_acc: 0.5223\n",
            "Epoch 20/100\n",
            "894/894 [==============================] - 0s 115us/step - loss: 0.7222 - acc: 0.6745 - val_loss: 1.0707 - val_acc: 0.5268\n",
            "Epoch 21/100\n",
            "894/894 [==============================] - 0s 110us/step - loss: 0.7274 - acc: 0.6812 - val_loss: 1.1159 - val_acc: 0.5089\n",
            "Epoch 22/100\n",
            "894/894 [==============================] - 0s 112us/step - loss: 0.7051 - acc: 0.7170 - val_loss: 1.0977 - val_acc: 0.5179\n",
            "Epoch 23/100\n",
            "894/894 [==============================] - 0s 105us/step - loss: 0.7341 - acc: 0.6644 - val_loss: 1.1198 - val_acc: 0.5000\n",
            "Epoch 24/100\n",
            "894/894 [==============================] - 0s 107us/step - loss: 0.6832 - acc: 0.7013 - val_loss: 1.0646 - val_acc: 0.5491\n",
            "Epoch 25/100\n",
            "894/894 [==============================] - 0s 108us/step - loss: 0.7251 - acc: 0.6846 - val_loss: 1.1013 - val_acc: 0.4911\n",
            "Epoch 26/100\n",
            "894/894 [==============================] - 0s 109us/step - loss: 0.6972 - acc: 0.7036 - val_loss: 1.0949 - val_acc: 0.5179\n",
            "Epoch 27/100\n",
            "894/894 [==============================] - 0s 115us/step - loss: 0.6930 - acc: 0.7013 - val_loss: 1.1332 - val_acc: 0.5268\n",
            "Epoch 28/100\n",
            "894/894 [==============================] - 0s 123us/step - loss: 0.6824 - acc: 0.7081 - val_loss: 1.0830 - val_acc: 0.5580\n",
            "Epoch 29/100\n",
            "894/894 [==============================] - 0s 124us/step - loss: 0.6929 - acc: 0.7025 - val_loss: 1.1452 - val_acc: 0.5089\n",
            "Epoch 30/100\n",
            "894/894 [==============================] - 0s 102us/step - loss: 0.6802 - acc: 0.7092 - val_loss: 1.1103 - val_acc: 0.4955\n",
            "Epoch 31/100\n",
            "894/894 [==============================] - 0s 107us/step - loss: 0.6957 - acc: 0.7081 - val_loss: 1.1632 - val_acc: 0.5268\n",
            "Epoch 32/100\n",
            "894/894 [==============================] - 0s 113us/step - loss: 0.6753 - acc: 0.7260 - val_loss: 1.1342 - val_acc: 0.5268\n",
            "Epoch 33/100\n",
            "894/894 [==============================] - 0s 113us/step - loss: 0.6599 - acc: 0.7192 - val_loss: 1.1476 - val_acc: 0.4821\n",
            "Epoch 34/100\n",
            "894/894 [==============================] - 0s 111us/step - loss: 0.6576 - acc: 0.7260 - val_loss: 1.2053 - val_acc: 0.5179\n",
            "Epoch 35/100\n",
            "894/894 [==============================] - 0s 106us/step - loss: 0.6723 - acc: 0.7114 - val_loss: 1.1084 - val_acc: 0.5357\n",
            "Epoch 36/100\n",
            "894/894 [==============================] - 0s 109us/step - loss: 0.6372 - acc: 0.7483 - val_loss: 1.1706 - val_acc: 0.4866\n",
            "Epoch 37/100\n",
            "894/894 [==============================] - 0s 107us/step - loss: 0.6391 - acc: 0.7360 - val_loss: 1.1648 - val_acc: 0.5179\n",
            "Epoch 38/100\n",
            "894/894 [==============================] - 0s 104us/step - loss: 0.6502 - acc: 0.7181 - val_loss: 1.2196 - val_acc: 0.4643\n",
            "Epoch 39/100\n",
            "894/894 [==============================] - 0s 117us/step - loss: 0.6320 - acc: 0.7327 - val_loss: 1.1393 - val_acc: 0.5089\n",
            "Epoch 40/100\n",
            "894/894 [==============================] - 0s 105us/step - loss: 0.6402 - acc: 0.7304 - val_loss: 1.1708 - val_acc: 0.4866\n",
            "Epoch 41/100\n",
            "894/894 [==============================] - 0s 106us/step - loss: 0.6291 - acc: 0.7282 - val_loss: 1.1206 - val_acc: 0.5000\n",
            "Epoch 42/100\n",
            "894/894 [==============================] - 0s 110us/step - loss: 0.6271 - acc: 0.7327 - val_loss: 1.1526 - val_acc: 0.4955\n",
            "Epoch 43/100\n",
            "894/894 [==============================] - 0s 108us/step - loss: 0.6273 - acc: 0.7539 - val_loss: 1.1574 - val_acc: 0.5134\n",
            "Epoch 44/100\n",
            "894/894 [==============================] - 0s 113us/step - loss: 0.5935 - acc: 0.7550 - val_loss: 1.2758 - val_acc: 0.5000\n",
            "Epoch 45/100\n",
            "894/894 [==============================] - 0s 107us/step - loss: 0.6044 - acc: 0.7584 - val_loss: 1.2261 - val_acc: 0.4464\n",
            "Epoch 46/100\n",
            "894/894 [==============================] - 0s 107us/step - loss: 0.6048 - acc: 0.7629 - val_loss: 1.1771 - val_acc: 0.5089\n",
            "Epoch 47/100\n",
            "894/894 [==============================] - 0s 108us/step - loss: 0.6166 - acc: 0.7584 - val_loss: 1.1562 - val_acc: 0.5000\n",
            "Epoch 48/100\n",
            "894/894 [==============================] - 0s 118us/step - loss: 0.5931 - acc: 0.7729 - val_loss: 1.2176 - val_acc: 0.5045\n",
            "Epoch 49/100\n",
            "894/894 [==============================] - 0s 115us/step - loss: 0.5884 - acc: 0.7640 - val_loss: 1.2820 - val_acc: 0.5000\n",
            "Epoch 50/100\n",
            "894/894 [==============================] - 0s 103us/step - loss: 0.5852 - acc: 0.7752 - val_loss: 1.2985 - val_acc: 0.5223\n",
            "Epoch 51/100\n",
            "894/894 [==============================] - 0s 111us/step - loss: 0.5802 - acc: 0.7696 - val_loss: 1.3210 - val_acc: 0.4018\n",
            "Epoch 52/100\n",
            "894/894 [==============================] - 0s 113us/step - loss: 0.5569 - acc: 0.7875 - val_loss: 1.2369 - val_acc: 0.5045\n",
            "Epoch 53/100\n",
            "894/894 [==============================] - 0s 113us/step - loss: 0.5691 - acc: 0.7740 - val_loss: 1.1962 - val_acc: 0.4509\n",
            "Epoch 54/100\n",
            "894/894 [==============================] - 0s 107us/step - loss: 0.5518 - acc: 0.7740 - val_loss: 1.2750 - val_acc: 0.4911\n",
            "Epoch 55/100\n",
            "894/894 [==============================] - 0s 92us/step - loss: 0.5619 - acc: 0.7785 - val_loss: 1.2171 - val_acc: 0.5089\n",
            "Epoch 56/100\n",
            "894/894 [==============================] - 0s 93us/step - loss: 0.5493 - acc: 0.7808 - val_loss: 1.2575 - val_acc: 0.5045\n",
            "Epoch 57/100\n",
            "894/894 [==============================] - 0s 89us/step - loss: 0.5546 - acc: 0.7808 - val_loss: 1.1791 - val_acc: 0.4866\n",
            "Epoch 58/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.5548 - acc: 0.7785 - val_loss: 1.1902 - val_acc: 0.4911\n",
            "Epoch 59/100\n",
            "894/894 [==============================] - 0s 93us/step - loss: 0.5450 - acc: 0.7852 - val_loss: 1.2142 - val_acc: 0.5268\n",
            "Epoch 60/100\n",
            "894/894 [==============================] - 0s 95us/step - loss: 0.5346 - acc: 0.7897 - val_loss: 1.2346 - val_acc: 0.5045\n",
            "Epoch 61/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.5274 - acc: 0.8031 - val_loss: 1.2028 - val_acc: 0.5402\n",
            "Epoch 62/100\n",
            "894/894 [==============================] - 0s 86us/step - loss: 0.5158 - acc: 0.8020 - val_loss: 1.2451 - val_acc: 0.5045\n",
            "Epoch 63/100\n",
            "894/894 [==============================] - 0s 90us/step - loss: 0.5156 - acc: 0.8031 - val_loss: 1.1829 - val_acc: 0.5268\n",
            "Epoch 64/100\n",
            "894/894 [==============================] - 0s 91us/step - loss: 0.5171 - acc: 0.7919 - val_loss: 1.2250 - val_acc: 0.4777\n",
            "Epoch 65/100\n",
            "894/894 [==============================] - 0s 93us/step - loss: 0.5206 - acc: 0.7953 - val_loss: 1.3728 - val_acc: 0.4866\n",
            "Epoch 66/100\n",
            "894/894 [==============================] - 0s 96us/step - loss: 0.5306 - acc: 0.7808 - val_loss: 1.2313 - val_acc: 0.4777\n",
            "Epoch 67/100\n",
            "894/894 [==============================] - 0s 89us/step - loss: 0.4971 - acc: 0.8098 - val_loss: 1.3886 - val_acc: 0.4196\n",
            "Epoch 68/100\n",
            "894/894 [==============================] - 0s 101us/step - loss: 0.5080 - acc: 0.8098 - val_loss: 1.2054 - val_acc: 0.5357\n",
            "Epoch 69/100\n",
            "894/894 [==============================] - 0s 92us/step - loss: 0.4921 - acc: 0.8098 - val_loss: 1.3863 - val_acc: 0.4955\n",
            "Epoch 70/100\n",
            "894/894 [==============================] - 0s 96us/step - loss: 0.4779 - acc: 0.8210 - val_loss: 1.4262 - val_acc: 0.5134\n",
            "Epoch 71/100\n",
            "894/894 [==============================] - 0s 100us/step - loss: 0.4898 - acc: 0.8121 - val_loss: 1.2220 - val_acc: 0.4955\n",
            "Epoch 72/100\n",
            "894/894 [==============================] - 0s 89us/step - loss: 0.4855 - acc: 0.8098 - val_loss: 1.2171 - val_acc: 0.5179\n",
            "Epoch 73/100\n",
            "894/894 [==============================] - 0s 89us/step - loss: 0.4766 - acc: 0.8289 - val_loss: 1.4764 - val_acc: 0.5000\n",
            "Epoch 74/100\n",
            "894/894 [==============================] - 0s 97us/step - loss: 0.4820 - acc: 0.8065 - val_loss: 1.2674 - val_acc: 0.5268\n",
            "Epoch 75/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.4602 - acc: 0.8266 - val_loss: 1.2611 - val_acc: 0.5179\n",
            "Epoch 76/100\n",
            "894/894 [==============================] - 0s 95us/step - loss: 0.4781 - acc: 0.8266 - val_loss: 1.3263 - val_acc: 0.4643\n",
            "Epoch 77/100\n",
            "894/894 [==============================] - 0s 93us/step - loss: 0.4499 - acc: 0.8479 - val_loss: 1.2539 - val_acc: 0.5134\n",
            "Epoch 78/100\n",
            "894/894 [==============================] - 0s 90us/step - loss: 0.4483 - acc: 0.8322 - val_loss: 1.2752 - val_acc: 0.4911\n",
            "Epoch 79/100\n",
            "894/894 [==============================] - 0s 89us/step - loss: 0.4706 - acc: 0.8210 - val_loss: 1.3897 - val_acc: 0.4732\n",
            "Epoch 80/100\n",
            "894/894 [==============================] - 0s 90us/step - loss: 0.4429 - acc: 0.8546 - val_loss: 1.3105 - val_acc: 0.4554\n",
            "Epoch 81/100\n",
            "894/894 [==============================] - 0s 90us/step - loss: 0.4527 - acc: 0.8468 - val_loss: 1.2705 - val_acc: 0.4911\n",
            "Epoch 82/100\n",
            "894/894 [==============================] - 0s 90us/step - loss: 0.4311 - acc: 0.8423 - val_loss: 1.2631 - val_acc: 0.5134\n",
            "Epoch 83/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.4269 - acc: 0.8468 - val_loss: 1.4021 - val_acc: 0.4911\n",
            "Epoch 84/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.4461 - acc: 0.8378 - val_loss: 1.4131 - val_acc: 0.5045\n",
            "Epoch 85/100\n",
            "894/894 [==============================] - 0s 92us/step - loss: 0.4184 - acc: 0.8557 - val_loss: 1.2645 - val_acc: 0.5357\n",
            "Epoch 86/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.4110 - acc: 0.8523 - val_loss: 1.3145 - val_acc: 0.4688\n",
            "Epoch 87/100\n",
            "894/894 [==============================] - 0s 100us/step - loss: 0.4136 - acc: 0.8546 - val_loss: 1.3161 - val_acc: 0.4866\n",
            "Epoch 88/100\n",
            "894/894 [==============================] - 0s 93us/step - loss: 0.4166 - acc: 0.8568 - val_loss: 1.3240 - val_acc: 0.5089\n",
            "Epoch 89/100\n",
            "894/894 [==============================] - 0s 90us/step - loss: 0.4246 - acc: 0.8468 - val_loss: 1.6960 - val_acc: 0.5000\n",
            "Epoch 90/100\n",
            "894/894 [==============================] - 0s 91us/step - loss: 0.4135 - acc: 0.8468 - val_loss: 1.4442 - val_acc: 0.3973\n",
            "Epoch 91/100\n",
            "894/894 [==============================] - 0s 89us/step - loss: 0.4119 - acc: 0.8479 - val_loss: 1.4809 - val_acc: 0.5089\n",
            "Epoch 92/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.3879 - acc: 0.8680 - val_loss: 1.3146 - val_acc: 0.5000\n",
            "Epoch 93/100\n",
            "894/894 [==============================] - 0s 99us/step - loss: 0.3911 - acc: 0.8613 - val_loss: 1.2938 - val_acc: 0.5089\n",
            "Epoch 94/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.3986 - acc: 0.8557 - val_loss: 1.3459 - val_acc: 0.5357\n",
            "Epoch 95/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.3795 - acc: 0.8702 - val_loss: 1.3195 - val_acc: 0.5000\n",
            "Epoch 96/100\n",
            "894/894 [==============================] - 0s 92us/step - loss: 0.3763 - acc: 0.8781 - val_loss: 1.2985 - val_acc: 0.4777\n",
            "Epoch 97/100\n",
            "894/894 [==============================] - 0s 93us/step - loss: 0.3912 - acc: 0.8613 - val_loss: 1.3996 - val_acc: 0.4911\n",
            "Epoch 98/100\n",
            "894/894 [==============================] - 0s 97us/step - loss: 0.3842 - acc: 0.8736 - val_loss: 1.3465 - val_acc: 0.4732\n",
            "Epoch 99/100\n",
            "894/894 [==============================] - 0s 94us/step - loss: 0.3584 - acc: 0.8859 - val_loss: 1.3875 - val_acc: 0.4866\n",
            "Epoch 100/100\n",
            "894/894 [==============================] - 0s 89us/step - loss: 0.3534 - acc: 0.8803 - val_loss: 1.4505 - val_acc: 0.4821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5387d9d198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    }
  ]
}